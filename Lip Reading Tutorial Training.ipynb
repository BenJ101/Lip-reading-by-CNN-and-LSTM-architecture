{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Load keras package needed\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os # drectory library\n",
    "import cv2 # image processing library\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Input\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import TimeDistributed\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "# Fix random seed\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 28 # input frame numbers for LSTM\n",
    "n_labels = 4 # Number of Dataset Labels\n",
    "Learning_rate = 0.0001 # Oprimizers lr, in this case, for adam\n",
    "batch_size = 32\n",
    "validation_ratio = 0.2 \n",
    "num_epochs = 10\n",
    "img_col = 224 # Transfer model input size ( MobileNet )\n",
    "img_row = 224 # Transfer model input size ( MobileNet )\n",
    "img_channel = 3 # RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Data is:  200\n",
      "Dataset shape is (200, 28, 224, 224, 3) (size, timestep, column, row, channel)\n",
      "Label shape is (200, 4) (size, label onehot vector)\n"
     ]
    }
   ],
   "source": [
    "# 1. Creating Datasets\n",
    "# define temporary empty list for load\n",
    "data = []\n",
    "label = []\n",
    "Totalnb = 0\n",
    "path = 'C:\\Intro to AI\\LipReading\\lipread_mp4'\n",
    "folder = 'test'\n",
    "# loop through each label (i)\n",
    "    # each label look at train folder\n",
    "    # in train folder loop through mp4 files (j) file\n",
    "    # create a folder and add that mp4 and metadata to a folder\n",
    "            # create jpg files from mp4 (k) frame in the folder\n",
    "            \n",
    "# Load Dataset\n",
    "path = 'C:\\Intro to AI\\LipReading\\lipread_mp4'\n",
    "# Loop through all labels\n",
    "for i, ind_label in enumerate(os.listdir(path)):\n",
    "    # go through train folder\n",
    "    for j, file in enumerate(os.listdir(os.path.join(path, ind_label, folder))):\n",
    "        # loop through all jpgs in folder\n",
    "        temp = []\n",
    "        jpgs = os.listdir(os.path.join(path, ind_label, folder, file))\n",
    "        jpgs = [f for f in jpgs if f.endswith('.jpg')]\n",
    "        for k, frame in enumerate(jpgs):\n",
    "            name = os.path.join(path, ind_label, folder, file, frame)\n",
    "            img = cv2.imread(name)\n",
    "            res = cv2.resize(img, dsize=(img_col, img_row), interpolation=cv2.INTER_CUBIC)\n",
    "            temp.append(res)\n",
    "        label.append(i)        \n",
    "        data.append(temp)\n",
    "        Totalnb += 1\n",
    "print(\"Total Number of Data is: \", Totalnb)\n",
    "\n",
    "# Convert List to numpy array, for Keras use\n",
    "Train_label = np.eye(n_labels)[label] # One-hot encoding by np array function\n",
    "Train_data = np.array(data)\n",
    "print(\"Dataset shape is\",Train_data.shape, \"(size, timestep, column, row, channel)\")\n",
    "print(\"Label shape is\",Train_label.shape,\"(size, label onehot vector)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling dataset for input fit function\n",
    "# if don`t, can`t train model entirely\n",
    "x = np.arange(Train_label.shape[0])\n",
    "np.random.shuffle(x)\n",
    "# same order shuffle is needed\n",
    "Train_label = Train_label[x]\n",
    "Train_data = Train_data[x]\n",
    "\n",
    "# declare data for training and validation, if you want, you can seperate testset from this\n",
    "X_train=Train_data[0:Totalnb,:]\n",
    "Y_train=Train_label[0:Totalnb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benjo\\anaconda3\\envs\\AICW\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 351s 65s/step - loss: 1.4275 - accuracy: 0.2562 - val_loss: 1.4226 - val_accuracy: 0.2000\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 243s 51s/step - loss: 1.3201 - accuracy: 0.3875 - val_loss: 1.3821 - val_accuracy: 0.3250\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 285s 62s/step - loss: 1.2476 - accuracy: 0.5375 - val_loss: 1.4022 - val_accuracy: 0.2500\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 278s 56s/step - loss: 1.1728 - accuracy: 0.5562 - val_loss: 1.4185 - val_accuracy: 0.2750\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 269s 60s/step - loss: 1.0388 - accuracy: 0.6625 - val_loss: 1.4456 - val_accuracy: 0.2750\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 1346s 266s/step - loss: 0.9484 - accuracy: 0.7625 - val_loss: 1.4448 - val_accuracy: 0.2750\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 313s 69s/step - loss: 0.8686 - accuracy: 0.8062 - val_loss: 1.3997 - val_accuracy: 0.3500\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 3568s 885s/step - loss: 0.7884 - accuracy: 0.8125 - val_loss: 1.4585 - val_accuracy: 0.3250\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 117s 22s/step - loss: 0.7401 - accuracy: 0.7875 - val_loss: 1.4711 - val_accuracy: 0.3750\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 125s 28s/step - loss: 0.6403 - accuracy: 0.8750 - val_loss: 1.4469 - val_accuracy: 0.3250\n"
     ]
    }
   ],
   "source": [
    "# 2. Buliding a Model\n",
    "# declare input layer for CNN+LSTM architecture\n",
    "video = Input(shape=(timesteps,img_col,img_row,img_channel))\n",
    "# Load transfer learning model that you want\n",
    "model = applications.MobileNet(input_shape=(img_col,img_row,img_channel), weights='imagenet', include_top=False)\n",
    "model.trainable = False\n",
    "# FC Dense Layer\n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "cnn_out = Dense(128, activation=\"relu\")(x)\n",
    "# Construct CNN model \n",
    "Lstm_inp = Model(inputs=model.input, outputs=cnn_out)\n",
    "# Distribute CNN output by timesteps \n",
    "encoded_frames = TimeDistributed(Lstm_inp)(video)\n",
    "# Contruct LSTM model \n",
    "encoded_sequence = LSTM(256)(encoded_frames)\n",
    "hidden_Drop = Dropout(0.3)(encoded_sequence)\n",
    "hidden_layer = Dense(128, activation=\"relu\")(encoded_sequence)\n",
    "outputs = Dense(n_labels, activation=\"softmax\")(hidden_layer)\n",
    "# Contruct CNN+LSTM model \n",
    "model = Model([video], outputs)\n",
    "# 3. Setting up the Model Learning Process\n",
    "# Model Compile \n",
    "adam = keras.optimizers.Adam(lr=Learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=adam, metrics=[\"accuracy\"])\n",
    "\n",
    "# 4. Training the Model\n",
    "hist = model.fit(X_train, Y_train, batch_size=batch_size, validation_split=validation_ratio, shuffle=True, epochs=num_epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPool3D, Activation, Reshape, SpatialDropout3D, BatchNormalization, TimeDistributed, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_6 (Conv3D)           (None, 28, 128, 128, 128  10496     \n",
      "                             )                                   \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 28, 128, 128, 128  0         \n",
      "                             )                                   \n",
      "                                                                 \n",
      " max_pooling3d_6 (MaxPooling  (None, 28, 64, 64, 128)  0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_7 (Conv3D)           (None, 28, 64, 64, 256)   884992    \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 28, 64, 64, 256)   0         \n",
      "                                                                 \n",
      " max_pooling3d_7 (MaxPooling  (None, 28, 32, 32, 256)  0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_8 (Conv3D)           (None, 28, 32, 32, 75)    518475    \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 28, 32, 32, 75)    0         \n",
      "                                                                 \n",
      " max_pooling3d_8 (MaxPooling  (None, 28, 16, 16, 75)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 28, 19200)        0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 28, 256)          19792896  \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 28, 256)           0         \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 28, 256)          394240    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 28, 256)           0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 28, 5)             1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,602,384\n",
      "Trainable params: 21,602,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Lip  Net Architecture\n",
    "model = Sequential()\n",
    "model.add(Conv3D(128, 3, input_shape=(timesteps,img_col,img_row,img_channel), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(Conv3D(256, 3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(Conv3D(75, 3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Dense(n_labels+1, kernel_initializer='he_normal', activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "You must install pydot (`pip install pydot`) for model_to_dot to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvis_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m model_to_dot\n\u001b[0;32m      6\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mmatplotlib\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minline\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m SVG(model_to_dot(model, show_shapes\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39mcreate(prog\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdot\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msvg\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m plot_model\n\u001b[0;32m     10\u001b[0m plot_model(model, to_file\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmodel.png\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\benjo\\anaconda3\\envs\\AICW\\lib\\site-packages\\keras\\utils\\vis_utils.py:138\u001b[0m, in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi, subgraph, layer_range, show_layer_activations)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Wrapper\n\u001b[0;32m    137\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m check_pydot():\n\u001b[1;32m--> 138\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m    139\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou must install pydot (`pip install pydot`) for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    140\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmodel_to_dot to work.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    141\u001b[0m     )\n\u001b[0;32m    143\u001b[0m \u001b[39mif\u001b[39;00m subgraph:\n\u001b[0;32m    144\u001b[0m     dot \u001b[39m=\u001b[39m pydot\u001b[39m.\u001b[39mCluster(style\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdashed\u001b[39m\u001b[39m\"\u001b[39m, graph_name\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mname)\n",
      "\u001b[1;31mImportError\u001b[0m: You must install pydot (`pip install pydot`) for model_to_dot to work."
     ]
    }
   ],
   "source": [
    "# Model Architecture Visualization\n",
    "from IPython.display import SVG\n",
    "import pydot\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "%matplotlib inline\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))\n",
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 5. Confirm the Learning Process\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')  \n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')  \n",
    "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Using the Model\n",
    "model.save('Lib_Reading_10Frame_Model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AICW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "05719e2546c8fca1fe69ca477dcba2bb6c7a2282fa28278d39173186922e5f9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
