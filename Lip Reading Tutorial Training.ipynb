{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\benjo\\Documents\\GitHub\\Lip-reading-by-CNN-and-LSTM-architecture\\Lip Reading Tutorial Training.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/benjo/Documents/GitHub/Lip-reading-by-CNN-and-LSTM-architecture/Lip%20Reading%20Tutorial%20Training.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# 0. Load keras package needed\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/benjo/Documents/GitHub/Lip-reading-by-CNN-and-LSTM-architecture/Lip%20Reading%20Tutorial%20Training.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/benjo/Documents/GitHub/Lip-reading-by-CNN-and-LSTM-architecture/Lip%20Reading%20Tutorial%20Training.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/benjo/Documents/GitHub/Lip-reading-by-CNN-and-LSTM-architecture/Lip%20Reading%20Tutorial%20Training.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mkeras\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/benjo/Documents/GitHub/Lip-reading-by-CNN-and-LSTM-architecture/Lip%20Reading%20Tutorial%20Training.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m \u001b[39m# drectory library\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# 0. Load keras package needed\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os # drectory library\n",
    "import cv2 # image processing library\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Input\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "# Fix random seed\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 10 # input frame numbers for LSTM\n",
    "n_labels = 8 # Number of Dataset Labels\n",
    "Learning_rate = 0.0001 # Oprimizers lr, in this case, for adam\n",
    "batch_size = 32\n",
    "validation_ratio = 0.2 \n",
    "num_epochs = 50\n",
    "img_col = 128 # Transfer model input size ( MobileNet )\n",
    "img_row = 128 # Transfer model input size ( MobileNet )\n",
    "img_channel = 3 # RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Label number of Dataset is: 82\n",
      "1 Label number of Dataset is: 74\n",
      "2 Label number of Dataset is: 86\n",
      "3 Label number of Dataset is: 66\n",
      "4 Label number of Dataset is: 70\n",
      "5 Label number of Dataset is: 81\n",
      "6 Label number of Dataset is: 69\n",
      "7 Label number of Dataset is: 58\n",
      "Total Number of Data is 586\n",
      "Dataset shape is (586, 10, 128, 128, 3) (size, timestep, column, row, channel)\n",
      "Label shape is (586, 8) (size, label onehot vector)\n"
     ]
    }
   ],
   "source": [
    "# 1. Creating Datasets\n",
    "# define temporary empty list for load\n",
    "data = []\n",
    "label = []\n",
    "Totalnb = 0\n",
    "\n",
    "# Load Dataset\n",
    "for i in range(n_labels):\n",
    "    nb = 0\n",
    "    # Counting datasets in each labels\n",
    "    for root, dirs, files in os.walk('normalized cascade/dataset/' + str(i+1)): # set directory\n",
    "        for name in dirs:\n",
    "            nb = nb + 1\n",
    "    print(i,\"Label number of Dataset is:\",nb)\n",
    "    Totalnb = Totalnb + nb\n",
    "    # by Counting size, cross subfolder and read image data, resize image, and append list \n",
    "    for j in range(nb):\n",
    "        temp = []\n",
    "        for k in range(timesteps):\n",
    "            name = 'normalized cascade/dataset/' + str(i+1) + '/' + str(j+1) + '/' + str(k+1) + '.jpg'\n",
    "            img = cv2.imread(name)\n",
    "            res = cv2.resize(img, dsize=(img_col, img_row), interpolation=cv2.INTER_CUBIC)\n",
    "            temp.append(res)\n",
    "        label.append(i)        \n",
    "        data.append(temp)\n",
    "print(\"Total Number of Data is\",Totalnb)\n",
    "\n",
    "# Convert List to numpy array, for Keras use\n",
    "Train_label = np.eye(n_labels)[label] # One-hot encoding by np array function\n",
    "Train_data = np.array(data)\n",
    "print(\"Dataset shape is\",Train_data.shape, \"(size, timestep, column, row, channel)\")\n",
    "print(\"Label shape is\",Train_label.shape,\"(size, label onehot vector)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling dataset for input fit function\n",
    "# if don`t, can`t train model entirely\n",
    "x = np.arange(Train_label.shape[0])\n",
    "np.random.shuffle(x)\n",
    "# same order shuffle is needed\n",
    "Train_label = Train_label[x]\n",
    "Train_data = Train_data[x]\n",
    "\n",
    "# declare data for training and validation, if you want, you can seperate testset from this\n",
    "X_train=Train_data[0:Totalnb,:]\n",
    "Y_train=Train_label[0:Totalnb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 2. Buliding a Model\n",
    "# declare input layer for CNN+LSTM architecture\n",
    "video = Input(shape=(timesteps,img_col,img_row,img_channel))\n",
    "# Load transfer learning model that you want\n",
    "model = applications.MobileNet(input_shape=(img_col,img_row,img_channel), weights=\"imagenet\", include_top=False)\n",
    "model.trainable = False\n",
    "# FC Dense Layer\n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "cnn_out = Dense(128, activation=\"relu\")(x)\n",
    "# Construct CNN model \n",
    "Lstm_inp = Model(input=model.input, output=cnn_out)\n",
    "# Distribute CNN output by timesteps \n",
    "encoded_frames = TimeDistributed(Lstm_inp)(video)\n",
    "# Contruct LSTM model \n",
    "encoded_sequence = LSTM(256)(encoded_frames)\n",
    "hidden_Drop = Dropout(0.3)(encoded_sequence)\n",
    "hidden_layer = Dense(128, activation=\"relu\")(encoded_sequence)\n",
    "outputs = Dense(n_labels, activation=\"softmax\")(hidden_layer)\n",
    "# Contruct CNN+LSTM model \n",
    "model = Model([video], outputs)\n",
    "# 3. Setting up the Model Learning Process\n",
    "# Model Compile \n",
    "adam = keras.optimizers.Adam(lr=Learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=adam, metrics=[\"accuracy\"])\n",
    "\n",
    "# 4. Training the Model\n",
    "hist = model.fit(X_train, Y_train, batch_size=batch_size, validation_split=validation_ratio, shuffle=True, nb_epoch=num_epochs)\n",
    "\n",
    "# Model Architecture Visualization\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))\n",
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Confirm the Learning Process\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')  \n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')  \n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Using the Model\n",
    "model.save('Lib_Reading_10Frame_Model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "introtoai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "5435ee006ff91e0a81fcd65b15b41ef6288c2aa8fefebf0d6a8825cdd6537f1d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
