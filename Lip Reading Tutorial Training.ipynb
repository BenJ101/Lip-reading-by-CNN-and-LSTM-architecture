{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Load keras package needed\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os # drectory library\n",
    "import cv2 # image processing library\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Input\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.layers import TimeDistributed\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "# Fix random seed\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 27 # input frame numbers for LSTM\n",
    "n_labels = 3 # Number of Dataset Labels\n",
    "Learning_rate = 0.0001 # Oprimizers lr, in this case, for adam\n",
    "batch_size = 32\n",
    "validation_ratio = 0.2 \n",
    "num_epochs = 50\n",
    "img_col = 128 # Transfer model input size ( MobileNet )\n",
    "img_row = 128 # Transfer model input size ( MobileNet )\n",
    "img_channel = 3 # RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Label number of Dataset is: 4375\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) C:\\b\\abs_74oeeuevib\\croots\\recipe\\opencv-suite_1664548340488\\work\\modules\\imgproc\\src\\resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m     name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mC:/Users/benjo/OneDrive/Yr4/Intro to AI/Lip Reading/lipread_mp4/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(k\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.jpg\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     27\u001b[0m     img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(name)\n\u001b[1;32m---> 28\u001b[0m     res \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mresize(img, dsize\u001b[39m=\u001b[39;49m(img_col, img_row), interpolation\u001b[39m=\u001b[39;49mcv2\u001b[39m.\u001b[39;49mINTER_CUBIC)\n\u001b[0;32m     29\u001b[0m     temp\u001b[39m.\u001b[39mappend(res)\n\u001b[0;32m     30\u001b[0m label\u001b[39m.\u001b[39mappend(i)        \n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) C:\\b\\abs_74oeeuevib\\croots\\recipe\\opencv-suite_1664548340488\\work\\modules\\imgproc\\src\\resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "# 1. Creating Datasets\n",
    "# define temporary empty list for load\n",
    "data = []\n",
    "label = []\n",
    "Totalnb = 0\n",
    "\n",
    "# loop through each label (i)\n",
    "    # each label look at train folder\n",
    "    # in train folder loop through mp4 files (j) file\n",
    "    # create a folder and add that mp4 and metadata to a folder\n",
    "            # create jpg files from mp4 (k) frame in the folder\n",
    "            \n",
    "# Load Dataset\n",
    "for i in range(n_labels):\n",
    "    nb = 0\n",
    "    # Counting datasets in each labels\n",
    "    for root, dirs, files in os.walk('C:/Intro to AI/LipReading/lipread_mp4/'): # set directory\n",
    "        for name in dirs:\n",
    "            nb = nb + 1\n",
    "    print(i,\"Label number of Dataset is:\",nb)\n",
    "    Totalnb = Totalnb + nb\n",
    "    # by Counting size, cross subfolder and read image data, resize image, and append list \n",
    "    for j in range(nb):\n",
    "        temp = []\n",
    "        for k in range(timesteps): # Remove loop and change to extraction process for mp4 to jpg using cv2\n",
    "            name = 'C:/Users/benjo/OneDrive/Yr4/Intro to AI/Lip Reading/lipread_mp4/' + str(i+1) + '/' + 'train' + '/' + str(k+1) + '.jpg'\n",
    "            img = cv2.imread(name)\n",
    "            res = cv2.resize(img, dsize=(img_col, img_row), interpolation=cv2.INTER_CUBIC)\n",
    "            temp.append(res)\n",
    "        label.append(i)        \n",
    "        data.append(temp)\n",
    "print(\"Total Number of Data is\",Totalnb)\n",
    "\n",
    "# Convert List to numpy array, for Keras use\n",
    "Train_label = np.eye(n_labels)[label] # One-hot encoding by np array function\n",
    "Train_data = np.array(data)\n",
    "print(\"Dataset shape is\",Train_data.shape, \"(size, timestep, column, row, channel)\")\n",
    "print(\"Label shape is\",Train_label.shape,\"(size, label onehot vector)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling dataset for input fit function\n",
    "# if don`t, can`t train model entirely\n",
    "x = np.arange(Train_label.shape[0])\n",
    "np.random.shuffle(x)\n",
    "# same order shuffle is needed\n",
    "Train_label = Train_label[x]\n",
    "Train_data = Train_data[x]\n",
    "\n",
    "# declare data for training and validation, if you want, you can seperate testset from this\n",
    "X_train=Train_data[0:Totalnb,:]\n",
    "Y_train=Train_label[0:Totalnb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 2. Buliding a Model\n",
    "# declare input layer for CNN+LSTM architecture\n",
    "video = Input(shape=(timesteps,img_col,img_row,img_channel))\n",
    "# Load transfer learning model that you want\n",
    "model = applications.MobileNet(input_shape=(img_col,img_row,img_channel), weights=\"imagenet\", include_top=False)\n",
    "model.trainable = False\n",
    "# FC Dense Layer\n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "cnn_out = Dense(128, activation=\"relu\")(x)\n",
    "# Construct CNN model \n",
    "Lstm_inp = Model(input=model.input, output=cnn_out)\n",
    "# Distribute CNN output by timesteps \n",
    "encoded_frames = TimeDistributed(Lstm_inp)(video)\n",
    "# Contruct LSTM model \n",
    "encoded_sequence = LSTM(256)(encoded_frames)\n",
    "hidden_Drop = Dropout(0.3)(encoded_sequence)\n",
    "hidden_layer = Dense(128, activation=\"relu\")(encoded_sequence)\n",
    "outputs = Dense(n_labels, activation=\"softmax\")(hidden_layer)\n",
    "# Contruct CNN+LSTM model \n",
    "model = Model([video], outputs)\n",
    "# 3. Setting up the Model Learning Process\n",
    "# Model Compile \n",
    "adam = keras.optimizers.Adam(lr=Learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=adam, metrics=[\"accuracy\"])\n",
    "\n",
    "# 4. Training the Model\n",
    "hist = model.fit(X_train, Y_train, batch_size=batch_size, validation_split=validation_ratio, shuffle=True, nb_epoch=num_epochs)\n",
    "\n",
    "# Model Architecture Visualization\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))\n",
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Confirm the Learning Process\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')  \n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "acc_ax.plot(hist.history['acc'], 'b', label='train acc')  \n",
    "acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Using the Model\n",
    "model.save('Lib_Reading_10Frame_Model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lipreading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "13428ca5b44a4a9452cb06d4aa826f71385429b41d10a5b217fa3047f44ce11b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
