{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Load keras package needed\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os # drectory library\n",
    "import cv2 # image processing library\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Input\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import TimeDistributed\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "# Fix random seed\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 28 # input frame numbers for LSTM\n",
    "n_labels = 4 # Number of Dataset Labels\n",
    "Learning_rate = 0.0001 # Oprimizers lr, in this case, for adam\n",
    "batch_size = 32\n",
    "validation_ratio = 0.2 \n",
    "num_epochs = 10\n",
    "img_col = 224 # Transfer model input size ( MobileNet )\n",
    "img_row = 224 # Transfer model input size ( MobileNet )\n",
    "img_channel = 3 # RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Data is:  200\n",
      "Dataset shape is (200, 28, 224, 224, 3) (size, timestep, column, row, channel)\n",
      "Label shape is (200, 4) (size, label onehot vector)\n"
     ]
    }
   ],
   "source": [
    "# 1. Creating Datasets\n",
    "# define temporary empty list for load\n",
    "data = []\n",
    "label = []\n",
    "Totalnb = 0\n",
    "path = 'C:\\Intro to AI\\LipReading\\lipread_mp4'\n",
    "folder = 'test'\n",
    "# loop through each label (i)\n",
    "    # each label look at train folder\n",
    "    # in train folder loop through mp4 files (j) file\n",
    "    # create a folder and add that mp4 and metadata to a folder\n",
    "            # create jpg files from mp4 (k) frame in the folder\n",
    "            \n",
    "# Load Dataset\n",
    "path = 'C:\\Intro to AI\\LipReading\\lipread_mp4'\n",
    "# Loop through all labels\n",
    "for i, ind_label in enumerate(os.listdir(path)):\n",
    "    # go through train folder\n",
    "    for j, file in enumerate(os.listdir(os.path.join(path, ind_label, folder))):\n",
    "        # loop through all jpgs in folder\n",
    "        temp = []\n",
    "        jpgs = os.listdir(os.path.join(path, ind_label, folder, file))\n",
    "        jpgs = [f for f in jpgs if f.endswith('.jpg')]\n",
    "        for k, frame in enumerate(jpgs):\n",
    "            name = os.path.join(path, ind_label, folder, file, frame)\n",
    "            img = cv2.imread(name)\n",
    "            res = cv2.resize(img, dsize=(img_col, img_row), interpolation=cv2.INTER_CUBIC)\n",
    "            temp.append(res)\n",
    "        label.append(i)        \n",
    "        data.append(temp)\n",
    "        Totalnb += 1\n",
    "print(\"Total Number of Data is: \", Totalnb)\n",
    "\n",
    "# Convert List to numpy array, for Keras use\n",
    "Train_label = np.eye(n_labels)[label] # One-hot encoding by np array function\n",
    "Train_data = np.array(data)\n",
    "print(\"Dataset shape is\",Train_data.shape, \"(size, timestep, column, row, channel)\")\n",
    "print(\"Label shape is\",Train_label.shape,\"(size, label onehot vector)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling dataset for input fit function\n",
    "# if don`t, can`t train model entirely\n",
    "x = np.arange(Train_label.shape[0])\n",
    "np.random.shuffle(x)\n",
    "# same order shuffle is needed\n",
    "Train_label = Train_label[x]\n",
    "Train_data = Train_data[x]\n",
    "\n",
    "# declare data for training and validation, if you want, you can seperate testset from this\n",
    "X_train=Train_data[0:Totalnb,:]\n",
    "Y_train=Train_label[0:Totalnb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benjo\\anaconda3\\envs\\AICW\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m\"\u001b[39m, optimizer\u001b[39m=\u001b[39madam, metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m     29\u001b[0m \u001b[39m# 4. Training the Model\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m hist \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, Y_train, batch_size\u001b[39m=\u001b[39;49mbatch_size, validation_split\u001b[39m=\u001b[39;49mvalidation_ratio, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, epochs\u001b[39m=\u001b[39;49mnum_epochs)\n",
      "File \u001b[1;32mc:\\Users\\benjo\\anaconda3\\envs\\AICW\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\benjo\\anaconda3\\envs\\AICW\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\benjo\\anaconda3\\envs\\AICW\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\benjo\\anaconda3\\envs\\AICW\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\benjo\\anaconda3\\envs\\AICW\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:980\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    976\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    977\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    978\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    979\u001b[0m     \u001b[39m# stateless function.\u001b[39;00m\n\u001b[1;32m--> 980\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    981\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    982\u001b[0m   _, _, filtered_flat_args \u001b[39m=\u001b[39m (\n\u001b[0;32m    983\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mcanonicalize_function_inputs(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    984\u001b[0m           \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n",
      "File \u001b[1;32mc:\\Users\\benjo\\anaconda3\\envs\\AICW\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\benjo\\anaconda3\\envs\\AICW\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\benjo\\anaconda3\\envs\\AICW\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\benjo\\anaconda3\\envs\\AICW\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 2. Buliding a Model\n",
    "# declare input layer for CNN+LSTM architecture\n",
    "video = Input(shape=(timesteps,img_col,img_row,img_channel))\n",
    "# Load transfer learning model that you want\n",
    "model = applications.MobileNet(input_shape=(img_col,img_row,img_channel), weights='imagenet', include_top=False)\n",
    "model.trainable = False\n",
    "# FC Dense Layer\n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "cnn_out = Dense(128, activation=\"relu\")(x)\n",
    "# Construct CNN model \n",
    "Lstm_inp = Model(inputs=model.input, outputs=cnn_out)\n",
    "# Distribute CNN output by timesteps \n",
    "encoded_frames = TimeDistributed(Lstm_inp)(video)\n",
    "# Contruct LSTM model \n",
    "encoded_sequence = LSTM(256)(encoded_frames)\n",
    "hidden_Drop = Dropout(0.3)(encoded_sequence)\n",
    "hidden_layer = Dense(128, activation=\"relu\")(encoded_sequence)\n",
    "outputs = Dense(n_labels, activation=\"softmax\")(hidden_layer)\n",
    "# Contruct CNN+LSTM model \n",
    "model = Model([video], outputs)\n",
    "# 3. Setting up the Model Learning Process\n",
    "# Model Compile \n",
    "adam = keras.optimizers.Adam(lr=Learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=adam, metrics=[\"accuracy\"])\n",
    "\n",
    "# 4. Training the Model\n",
    "hist = model.fit(X_train, Y_train, batch_size=batch_size, validation_split=validation_ratio, shuffle=True, epochs=num_epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPool3D, Activation, Reshape, SpatialDropout3D, BatchNormalization, TimeDistributed, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_6 (Conv3D)           (None, 28, 128, 128, 128  10496     \n",
      "                             )                                   \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 28, 128, 128, 128  0         \n",
      "                             )                                   \n",
      "                                                                 \n",
      " max_pooling3d_6 (MaxPooling  (None, 28, 64, 64, 128)  0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_7 (Conv3D)           (None, 28, 64, 64, 256)   884992    \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 28, 64, 64, 256)   0         \n",
      "                                                                 \n",
      " max_pooling3d_7 (MaxPooling  (None, 28, 32, 32, 256)  0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_8 (Conv3D)           (None, 28, 32, 32, 75)    518475    \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 28, 32, 32, 75)    0         \n",
      "                                                                 \n",
      " max_pooling3d_8 (MaxPooling  (None, 28, 16, 16, 75)   0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 28, 19200)        0         \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 28, 256)          19792896  \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 28, 256)           0         \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 28, 256)          394240    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 28, 256)           0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 28, 5)             1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,602,384\n",
      "Trainable params: 21,602,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Lip  Net Architecture\n",
    "model = Sequential()\n",
    "model.add(Conv3D(128, 3, input_shape=(timesteps,img_col,img_row,img_channel), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(Conv3D(256, 3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(Conv3D(75, 3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Dense(n_labels+1, kernel_initializer='he_normal', activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "You must install pydot (`pip install pydot`) for model_to_dot to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvis_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m model_to_dot\n\u001b[0;32m      6\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mmatplotlib\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minline\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m SVG(model_to_dot(model, show_shapes\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39mcreate(prog\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdot\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msvg\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m plot_model\n\u001b[0;32m     10\u001b[0m plot_model(model, to_file\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmodel.png\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\benjo\\anaconda3\\envs\\AICW\\lib\\site-packages\\keras\\utils\\vis_utils.py:138\u001b[0m, in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi, subgraph, layer_range, show_layer_activations)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Wrapper\n\u001b[0;32m    137\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m check_pydot():\n\u001b[1;32m--> 138\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[0;32m    139\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou must install pydot (`pip install pydot`) for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    140\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmodel_to_dot to work.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    141\u001b[0m     )\n\u001b[0;32m    143\u001b[0m \u001b[39mif\u001b[39;00m subgraph:\n\u001b[0;32m    144\u001b[0m     dot \u001b[39m=\u001b[39m pydot\u001b[39m.\u001b[39mCluster(style\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdashed\u001b[39m\u001b[39m\"\u001b[39m, graph_name\u001b[39m=\u001b[39mmodel\u001b[39m.\u001b[39mname)\n",
      "\u001b[1;31mImportError\u001b[0m: You must install pydot (`pip install pydot`) for model_to_dot to work."
     ]
    }
   ],
   "source": [
    "# Model Architecture Visualization\n",
    "from IPython.display import SVG\n",
    "import pydot\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "%matplotlib inline\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))\n",
    "\n",
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m fig, loss_ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots()\n\u001b[0;32m      5\u001b[0m acc_ax \u001b[39m=\u001b[39m loss_ax\u001b[39m.\u001b[39mtwinx()\n\u001b[1;32m----> 6\u001b[0m loss_ax\u001b[39m.\u001b[39mplot(hist\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain loss\u001b[39m\u001b[39m'\u001b[39m)  \n\u001b[0;32m      7\u001b[0m loss_ax\u001b[39m.\u001b[39mplot(hist\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval loss\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m acc_ax\u001b[39m.\u001b[39mplot(hist\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain acc\u001b[39m\u001b[39m'\u001b[39m)  \n",
      "\u001b[1;31mNameError\u001b[0m: name 'hist' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. Confirm the Learning Process\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')  \n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')  \n",
    "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Using the Model\n",
    "model.save('Lib_Reading_10Frame_Model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AICW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "05719e2546c8fca1fe69ca477dcba2bb6c7a2282fa28278d39173186922e5f9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
